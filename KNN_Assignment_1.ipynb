{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "617722c8",
   "metadata": {},
   "source": [
    "#### Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ff41b",
   "metadata": {},
   "source": [
    "1. KNN - K Nearest Neighors \n",
    "2. KNN is supervised machine learning algorithm used for classification and regression and in this the input consists of the k closest training examples in a data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abeea21",
   "metadata": {},
   "source": [
    "#### Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f706b",
   "metadata": {},
   "source": [
    "- The value of K is the square root of N,in which N is the no. of samples. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7418f397",
   "metadata": {},
   "source": [
    "#### Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b6a578",
   "metadata": {},
   "source": [
    "1. In KNN classifier,we use binary or any other classification and depending on that,we find the major no. of nearest neighors we are getting and predicts the output. \n",
    "2. In KNN regressor,we find k nearest neighors and find their avg or if their are outliers,we prefer to find median insted of avg and predict the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381481d1",
   "metadata": {},
   "source": [
    "#### Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b85d11",
   "metadata": {},
   "source": [
    "1. Determine the no. of nearest neighors. \n",
    "2. Compute the distance between test sample and all the training samples \n",
    "3. Sort the distance and determine nearest neighors based on the Kth minimum distance. \n",
    "4. Assemble the categories of the nearest neighors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511c5c6f",
   "metadata": {},
   "source": [
    "#### Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1048f1c7",
   "metadata": {},
   "source": [
    "- It means there are some features which are less important or not important at all. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800222d1",
   "metadata": {},
   "source": [
    "#### Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486f9d14",
   "metadata": {},
   "source": [
    "- In KNN,each sample's missing values are imputed using the mean value of the k-neighors found in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697b20da",
   "metadata": {},
   "source": [
    "#### Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8c53a8",
   "metadata": {},
   "source": [
    "1. If I want to classify the laptop on the base of body color,screen size,RAM,ROM,Resolution, then I will use KNN classifier.\n",
    "2. If I want to find average selling of classmate books all over india,then I will use KNN Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407221cc",
   "metadata": {},
   "source": [
    "#### Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks, and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f071a3e",
   "metadata": {},
   "source": [
    "- Strength - The accuracy and effectiveness of KNN algorithm is the strength of it. It is robust to handle incomplete data specially in small-medium sized datasets. \n",
    "\n",
    "- Weakness - We have to check for each and every neighor to find k nearest neighors,but it can be addressed by using Eigen values and Eigen vectors in the Eigen decomposition transformation in PCA(Principal Component Analysis)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab27a9a",
   "metadata": {},
   "source": [
    "#### Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa6059",
   "metadata": {},
   "source": [
    "1. The firstmost difference between Euclidean and Manhattan distance is the p-value used in algorithm,i.e.,the p_value of Manhattan distance is 1 and Euclidean distance is 2 and by default in algorithm  the p-value is set to 2 i.e.,Euclidean distance. \n",
    "2. The Euclidean distance is the shortest path between the source and the destination which is a straight line and Manhattan distance is sum of all the real distances between source and destination and each distance are always the straight line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a865c8",
   "metadata": {},
   "source": [
    "#### Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f9f8a3",
   "metadata": {},
   "source": [
    "- As KNN is distance-based algorithm,feature scaling is most important. \n",
    "- All the distance based algorithms are affected by the scale of the variables and the algorithm could be affected by the magnitude of this variables,so,the algorithm should not be biased towards variables with higher magnitude,we use feature scaling which is part of standardization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab68497f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
